{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8973aed2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import polars as pl\n",
    "import util\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LinearRegression\n",
    "import numpy as np\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84a04345",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = util.load_data().fetch(1_000_000)\n",
    "# df = util.load_data().collect()\n",
    "\n",
    "# Run preprocess.py to obtain the parquet dataset\n",
    "# df = pl.read_parquet('datasets/train.parquet')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af69c78f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a31e055e",
   "metadata": {},
   "source": [
    "## Data distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2011de25",
   "metadata": {},
   "outputs": [],
   "source": [
    "# NB: This plot takes a lot of time\n",
    "util.plot_distributions(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df988135",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(df['fare_amount'], bins=60, range=(0, 60))\n",
    "plt.title('Closeup - fare amount')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca701b23",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(df['pickup_latitude'], bins=60, range=(40.65, 40.85))\n",
    "plt.title('Closeup - pickup latitude')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0936fa5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(df['pickup_longitude'], bins=60, range=(-74.1, -73.75))\n",
    "plt.title('Closeup - pickup longitude')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4c70059",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(df['pickup_datetime'], bins=7)\n",
    "plt.title('Closeup - Timestamp')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77f6ac03",
   "metadata": {},
   "source": [
    "The distributions suggest the existence of unrealistic data (noise?) and outliers (hundres of passengers for one run, thosands of dollars for a single run). Min and max values show this very clearly. Before moving on with other statistics, it may be a good idea to clear the data further."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48c48e01",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c6fa9fc",
   "metadata": {},
   "source": [
    "### Passenger count\n",
    "According to the [NYC taxi commission](https://www.nyc.gov/site/tlc/passengers/passenger-frequently-asked-questions.page#:~:text=The%20maximum%20amount%20of%20passengers,of%20an%20adult%20passenger%20seated) the maximum number of passengers, for suitable vehicles, is five. An additional sixth person (child) is admitted. Thus, it is possible to consider all samples that exceed the number of six passengers to be noise. In fact, values greater than six are highly underrepresented."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f9a9f71",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.groupby('passenger_count').agg(pl.count()).sort('passenger_count')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5feda27f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.filter(pl.col('passenger_count') <= 6)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2632f50",
   "metadata": {},
   "source": [
    "## Analyzing spatial locations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe1d2f0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# train, test = train_test_split(df, test_size=0.2)\n",
    "# train, valid = train_test_split(train, test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e91ef84",
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_point_on_map(ax, x, y, points_area, image, markersize=.5, color='b', title=None):\n",
    "    left, right, bottom, top = points_area\n",
    "    ax.imshow(image, extent=(left, right, bottom, top))\n",
    "    ax.set_ylim(bottom, top)\n",
    "    ax.set_xlim(left, right)\n",
    "    ax.scatter(x, y, markersize, color)\n",
    "    if title is not None:\n",
    "        ax.title.set_text(str(title))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "813021fb",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "x = df['pickup_longitude'].append(df['dropoff_longitude'])\n",
    "y = df['pickup_latitude'].append(df['dropoff_latitude'])\n",
    "points_area = x.min(), x.max(), y.min(), y.max()\n",
    "\n",
    "# Make the area a square\n",
    "width = util.distance((points_area[0],points_area[2]), (points_area[1],points_area[2]))\n",
    "height = util.distance((points_area[0],points_area[2]), (points_area[0],points_area[3]))\n",
    "\n",
    "additional_space = (width - height)/2\n",
    "\n",
    "new_lat_min, _ = util.find_latitude_correction((points_area[0],points_area[2]), additional_space, b=-1)\n",
    "new_lat_max, _ = util.find_latitude_correction((points_area[0],points_area[3]), additional_space, b=1)\n",
    "\n",
    "points_area = points_area[0], points_area[1], new_lat_min, new_lat_max\n",
    "# print(util.distance((points_area[0],points_area[2]), (points_area[1],points_area[2])))\n",
    "# print(util.distance((points_area[1],points_area[2]), (points_area[1],points_area[3])))\n",
    "# print(util.distance((points_area[1],points_area[3]), (points_area[0],points_area[3])))\n",
    "# print(util.distance((points_area[0],points_area[3]), (points_area[0],points_area[2])))\n",
    "\n",
    "url = 'https://b.basemaps.cartocdn.com/light_nolabels/{z}/{x}/{y}.png'\n",
    "image = util.new_york_map(points_area)\n",
    "\n",
    "plt.imshow(image)\n",
    "plt.show()\n",
    "print(points_area)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de1b3e8d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Remove points on ocean, not working at the moment\n",
    "ocean_pickup = df.select(\n",
    "    pl.struct(['pickup_longitude', 'pickup_latitude', 'dropoff_longitude', 'dropoff_latitude'])\n",
    "    .map(util.polars_point_on_ocean(points_area, pickup=True))\n",
    "    ).get_columns()[0].alias('ocean_pickup')\n",
    "print(\"pickup done\")\n",
    "ocean_dropoff = df.select(\n",
    "    pl.struct(['pickup_longitude', 'pickup_latitude', 'dropoff_longitude', 'dropoff_latitude'])\n",
    "    .map(util.polars_point_on_ocean(points_area, dropoff=True))\n",
    "    ).get_columns()[0].alias('ocean_dropoff')\n",
    "\n",
    "print('Pickups in the ocean', ocean_pickup.arg_true().shape[0])\n",
    "print('Dropoffs in the ocean', ocean_dropoff.arg_true().shape[0])\n",
    "print('Total ocean outlier samples',\n",
    "      (ocean_dropoff | ocean_pickup).arg_true().shape[0])\n",
    "\n",
    "outsiders_pickup = df.filter(ocean_pickup)\n",
    "outsiders_dropoff = df.filter(ocean_dropoff)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37652200",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(1, 2, figsize=(30, 30))\n",
    "\n",
    "print_point_on_map(axs[0], outsiders_pickup['pickup_longitude'], outsiders_pickup['pickup_latitude'], points_area, image, color='b', markersize=3)\n",
    "print_point_on_map(axs[1], outsiders_dropoff['dropoff_longitude'], outsiders_dropoff['dropoff_latitude'], points_area, image, color='r', markersize=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7857833",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.filter(~ocean_pickup & ~ocean_dropoff)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60f95cf0",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(1, 2, figsize=(50, 50))\n",
    "print_point_on_map(axs[0], df['pickup_longitude'], df['pickup_latitude'], points_area, image, color='b')\n",
    "print_point_on_map(axs[1], df['dropoff_longitude'], df['dropoff_latitude'], points_area, image, color='r')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "627ad8c8",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "timezone = -5\n",
    "lavorative_hours = (8, 18)\n",
    "\n",
    "day_hours = df.filter((pl.col(\"pickup_datetime\").dt.hour() > lavorative_hours[0]+timezone) & (pl.col(\"pickup_datetime\").dt.hour() < lavorative_hours[1]+timezone))\n",
    "night_hours = df.filter((pl.col(\"pickup_datetime\").dt.hour() <= lavorative_hours[0]+timezone) | (pl.col(\"pickup_datetime\").dt.hour() >= lavorative_hours[1]+timezone))\n",
    "\n",
    "print(len(day_hours), len(night_hours))\n",
    "\n",
    "x_day = day_hours['pickup_longitude'].append(day_hours['dropoff_longitude'])\n",
    "y_day = day_hours['pickup_latitude'].append(day_hours['dropoff_latitude'])\n",
    "\n",
    "x_night = night_hours['pickup_longitude'].append(night_hours['dropoff_longitude'])\n",
    "y_night = night_hours['pickup_latitude'].append(night_hours['dropoff_latitude'])\n",
    "\n",
    "fig, axs = plt.subplots(1, 2, figsize=(16, 16))\n",
    "print_point_on_map(axs[0], x_day, y_day, points_area, image, color='b', markersize=0.1)\n",
    "print_point_on_map(axs[1], x_night, y_night, points_area, image, color='r', markersize=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a92b483e",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "hours = []\n",
    "\n",
    "for h in range(5,29):\n",
    "    hour_df = df.filter(pl.col(\"pickup_datetime\").dt.hour() == h % 24)\n",
    "    hours.append((hour_df['pickup_longitude'].append(hour_df['dropoff_longitude']),\n",
    "                  hour_df['pickup_latitude'].append(hour_df['dropoff_latitude']),\n",
    "                  len(hour_df)))\n",
    "    \n",
    "fig, axs = plt.subplots(6, 4, figsize=(16, 20))\n",
    "for h in range(24):\n",
    "    print_point_on_map(axs[h//4, h % 4], hours[h][0], hours[h][1], points_area, image, color='b',\n",
    "                       title=f'{(h) % 24}. {hours[h][2]} rides', markersize=0.05)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5413203b",
   "metadata": {},
   "source": [
    "## Time\n",
    "Specific features have to be extracted from timestamps, based on periods and trends."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64c5ac89",
   "metadata": {},
   "source": [
    "### Monthly-Yearly trend\n",
    "\n",
    "The first thing to investigate is the presence of trends, as detrending data will eventually be necessary before looking for periods. Public transportation rarely becomes cheaper, (at least, that how it is in Bologna). The NYC taxi data spans for about six years, hence, let us look for a yearly trend"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b892cc9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(\n",
    "    *df.select(['pickup_datetime', 'fare_amount']).sort('pickup_datetime')\n",
    "    .groupby_dynamic('pickup_datetime', every='1y')\n",
    "    .agg(pl.mean('fare_amount'))\n",
    "    .get_columns())\n",
    "plt.title('Yearly average fare')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "811e68be",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.select(['pickup_datetime', 'fare_amount']).sort('pickup_datetime') \\\n",
    "  .groupby_dynamic('pickup_datetime', every='1y') \\\n",
    "  .agg(pl.col('fare_amount').std().alias('std'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "456be33f",
   "metadata": {},
   "source": [
    "Even though variance is pretty high, there is an unambiguous yearly trend (NYC is not that different from Bologna after all). In fact, it is a well known fact that public transportation fares in NYC have been adjusted over time to deal with inflation [2]. In particular, a notable increase happened between 2012 and 2013."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e54cb0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(\n",
    "    *df.select(['pickup_datetime', 'fare_amount']).sort('pickup_datetime')\n",
    "    .filter(pl.col('pickup_datetime').dt.year() == 2012)\n",
    "    .groupby_dynamic('pickup_datetime', every='1mo')\n",
    "    .agg(pl.mean('fare_amount'))\n",
    "    .get_columns())\n",
    "plt.title('Per-month average fares (2012)')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6490a13b",
   "metadata": {},
   "source": [
    "Further inspection shows that the gap happened in September 2012. In fact, historical record witnesses this. According to the *Fare and Lease Cap Report* of April 2013 [3], during fall 2012 fares have increased by 17%, apparently in order to handle a change in credit card processing fees.\n",
    "\n",
    "Approximating the trend is mandatory in order to proceed with the inspection of periods. Given its nature (inflation) it is acceptable to consider it linear. However, the big gap of September 2012 can be considered anomalous and would clearly skew the linear coefficients. For this reason, two linear trends are considered, with a discontinuity exactly in September 2012."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "652d2c92",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute the monthly average fares and split them before/after Sep 2012\n",
    "months_df = (\n",
    "    df.select(['pickup_datetime', 'fare_amount'])\n",
    "    .sort('pickup_datetime')\n",
    "    .groupby_dynamic('pickup_datetime', every='1mo')\n",
    "    .agg(pl.mean('fare_amount'))\n",
    ")\n",
    "\n",
    "months_pre2012_df = (\n",
    "    months_df.filter(pl.col('pickup_datetime') < pl.datetime(2012, 9, 1))\n",
    ")\n",
    "\n",
    "months_post2012_df = (\n",
    "    months_df.filter(pl.col('pickup_datetime') >= pl.datetime(2012, 9, 1))\n",
    ")\n",
    "\n",
    "# Sanity check on the dataframe shapes\n",
    "split_month_span = len(months_pre2012_df) + len(months_post2012_df)\n",
    "assert split_month_span == len(months_df)\n",
    "\n",
    "print('Total months', split_month_span)\n",
    "print('Months before Sep 2012:', len(months_pre2012_df))\n",
    "print('Months after Sep 2012:', len(months_post2012_df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abe2701b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fit two OLS regressors\n",
    "months_features = np.array(range(len(months_df))).reshape(-1, 1)\n",
    "months_pre2012_features = months_features[:len(months_pre2012_df)]\n",
    "months_post2012_features = months_features[len(months_pre2012_df):]\n",
    "\n",
    "trend_pre2012_regressor = LinearRegression(n_jobs=-1).fit(\n",
    "    months_pre2012_features, months_pre2012_df['fare_amount'])\n",
    "trend_post2012_regressor = LinearRegression(n_jobs=-1).fit(\n",
    "    months_post2012_features, months_post2012_df['fare_amount'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77658ac8",
   "metadata": {},
   "outputs": [],
   "source": [
    "trend_pre2012_pred = trend_pre2012_regressor.predict(months_pre2012_features)\n",
    "trend_post2012_pred = trend_post2012_regressor.predict(months_post2012_features)\n",
    "\n",
    "plt.figure(figsize=(40, 8))\n",
    "plt.plot(*months_df.get_columns())\n",
    "plt.plot(months_df['pickup_datetime'],  np.concatenate((trend_pre2012_pred, trend_post2012_pred)))\n",
    "plt.legend(('Monthly average fare', 'Linear average fare'), fontsize='xx-large')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3007ca53",
   "metadata": {},
   "source": [
    "The double-linear regression seems to be quite reasonable. This shall result in the extraction of a couple of dedicated features from the timestamps. However, which ones exactly will be discussed after an analysis on periods."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c89f382",
   "metadata": {},
   "source": [
    "### Periods\n",
    "A detrended/stationary series can now be computed in order to have a cleaner overview of the periods."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8113b398",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Detrend before plotting\n",
    "\n",
    "plt.figure(figsize=(40, 8))\n",
    "plt.plot(\n",
    "    *df.select(['pickup_datetime', 'fare_amount']).sort('pickup_datetime')\n",
    "    .groupby_dynamic('pickup_datetime', every='1mo')\n",
    "    .agg(pl.mean('fare_amount'))\n",
    "    .get_columns())\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ba09e14",
   "metadata": {},
   "outputs": [],
   "source": [
    "jfk_position = (40.653005, -73.797447)\n",
    "manhattan_position = (40.722433, -74.000845)\n",
    "precision = 0.01\n",
    "\n",
    "df_grt_2013 = df.filter((pl.col('pickup_datetime').is_between(pl.datetime(2013, 1, 1), pl.datetime(2100, 1, 1))))\n",
    "df_grt_2013 = df_grt_2013.with_column(pl.col(\"pickup_datetime\").dt.hour().alias('pickup_hour'))\n",
    "\n",
    "df_manhattan = df_grt_2013.filter(((pl.col('pickup_latitude').is_between(manhattan_position[0] - precision, manhattan_position[0] + precision, closed='both')) &\n",
    "                                 (pl.col('pickup_longitude').is_between(manhattan_position[1] - precision, manhattan_position[1] + precision, closed='both'))) |\n",
    "                                 ((pl.col('dropoff_latitude').is_between(manhattan_position[0] - precision, manhattan_position[0] + precision, closed='both')) &\n",
    "                                 (pl.col('dropoff_longitude').is_between(manhattan_position[1] - precision, manhattan_position[1] + precision, closed='both'))))\n",
    "\n",
    "df_jfk = df_grt_2013.filter(((pl.col('pickup_latitude').is_between(jfk_position[0] - precision, jfk_position[0] + precision, closed='both')) &\n",
    "                                 (pl.col('pickup_longitude').is_between(jfk_position[1] - precision, jfk_position[1] + precision, closed='both'))) |\n",
    "                                 ((pl.col('dropoff_latitude').is_between(jfk_position[0] - precision, jfk_position[0] + precision, closed='both')) &\n",
    "                                 (pl.col('dropoff_longitude').is_between(jfk_position[1] - precision, jfk_position[1] + precision, closed='both'))))\n",
    "\n",
    "\n",
    "print(f\"Number of samples from or to jfk: {len(df_jfk)}\")\n",
    "print(f\"Number of samples from or to manhattan: {len(df_manhattan)}\")\n",
    "\n",
    "fg, axs = plt.subplots(2,1, figsize=(40, 8))\n",
    "axs[0].hist(df_manhattan['pickup_hour'], bins=24)\n",
    "axs[0].title.set_text('Hour samples distribution from or to manhattan')\n",
    "\n",
    "axs[1].plot(\n",
    "    *df_manhattan.select(['pickup_hour', 'fare_amount'])\n",
    "    .groupby('pickup_hour')\n",
    "    .agg(pl.mean('fare_amount'))\n",
    "    .sort('pickup_hour')\n",
    "    .get_columns())\n",
    "axs[1].title.set_text(\"Mean hourly fare from or to manhattan\")\n",
    "\n",
    "plt.show()\n",
    "\n",
    "fg, axs = plt.subplots(2,1, figsize=(40, 8))\n",
    "\n",
    "axs[0].hist(df_jfk['pickup_hour'], bins=24)\n",
    "axs[0].title.set_text('Hour samples distribution from or to jfk')\n",
    "\n",
    "axs[1].plot(\n",
    "    *df_jfk.select(['pickup_hour', 'fare_amount'])\n",
    "    .groupby('pickup_hour')\n",
    "    .agg(pl.mean('fare_amount'))\n",
    "    .sort('pickup_hour')\n",
    "    .get_columns())\n",
    "axs[1].title.set_text(\"Mean hourly fare from or to jfk\")\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8753e50c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import importlib\n",
    "importlib.reload(util)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "1394ad46",
   "metadata": {},
   "source": [
    "# References\n",
    "*TODO: properly cite?*\n",
    "\n",
    "[2]: Why Subway and Bus Fares Are Likely to Rise Next Year, https://www.nytimes.com/2022/12/19/nyregion/why-subway-and-bus-fares-are-likely-to-rise-next-year.html\n",
    "\n",
    "[3]: Fare and Lease Cap Report: April 2013, https://a860-gpp.nyc.gov/concern/nyc_government_publications/jm214q472?locale=en\n",
    "\n",
    "[4]: norta - code for New Orleans Regional Transit Authority Data, https://git.bryanbrattlof.com/norta/about/"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "fare-prediction",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "vscode": {
   "interpreter": {
    "hash": "696c235b3b902a0ba4aa434fdc36a015b2219ccdfa906ae5c584142149033b59"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
