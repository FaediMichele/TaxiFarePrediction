{
    "cells": [
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "8973aed2",
            "metadata": {},
            "outputs": [],
            "source": [
                "import matplotlib.pyplot as plt\n",
                "import polars as pl\n",
                "import taxifare.data as data\n",
                "import taxifare.boroughs as boroughs\n",
                "from sklearn.model_selection import train_test_split\n",
                "from sklearn.linear_model import LinearRegression\n",
                "import seaborn as sns\n",
                "import numpy as np\n",
                "import math\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "84a04345",
            "metadata": {},
            "outputs": [],
            "source": [
                "df = data.load_data().fetch(500_000)\n",
                "# df = data.load_data().collect()\n",
                "\n",
                "# Run preprocess.py to obtain the parquet dataset\n",
                "# df = pl.read_parquet('datasets/train.parquet')\n",
                "df.head()"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "af69c78f",
            "metadata": {
                "scrolled": true
            },
            "outputs": [],
            "source": [
                "df.shape"
            ]
        },
        {
            "cell_type": "markdown",
            "id": "a31e055e",
            "metadata": {},
            "source": [
                "## Data distribution"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "2011de25",
            "metadata": {},
            "outputs": [],
            "source": [
                "# NB: This plot takes a lot of time\n",
                "data.plot_distributions(df)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "df988135",
            "metadata": {},
            "outputs": [],
            "source": [
                "plt.hist(df['fare_amount'], bins=60, range=(0, 60))\n",
                "plt.title('Closeup - fare amount')\n",
                "plt.show()"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "ca701b23",
            "metadata": {},
            "outputs": [],
            "source": [
                "plt.hist(df['pickup_latitude'], bins=60, range=(40.65, 40.85))\n",
                "plt.title('Closeup - pickup latitude')\n",
                "plt.show()"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "0936fa5c",
            "metadata": {},
            "outputs": [],
            "source": [
                "plt.hist(df['pickup_longitude'], bins=60, range=(-74.1, -73.75))\n",
                "plt.title('Closeup - pickup longitude')\n",
                "plt.show()"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "c4c70059",
            "metadata": {},
            "outputs": [],
            "source": [
                "plt.hist(df['pickup_datetime'], bins=7)\n",
                "plt.title('Closeup - Timestamp')\n",
                "plt.show()"
            ]
        },
        {
            "cell_type": "markdown",
            "id": "77f6ac03",
            "metadata": {},
            "source": [
                "The distributions suggest the existence of unrealistic data (noise?) and outliers (hundres of passengers for one run, thosands of dollars for a single run). Min and max values show this very clearly. Before moving on with other statistics, it may be a good idea to clear the data further."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "48c48e01",
            "metadata": {},
            "outputs": [],
            "source": [
                "df.describe()"
            ]
        },
        {
            "cell_type": "markdown",
            "id": "9c6fa9fc",
            "metadata": {},
            "source": [
                "### Passenger count\n",
                "According to the [NYC taxi commission](https://www.nyc.gov/site/tlc/passengers/passenger-frequently-asked-questions.page#:~:text=The%20maximum%20amount%20of%20passengers,of%20an%20adult%20passenger%20seated) the maximum number of passengers, for suitable vehicles, is five. An additional sixth person (child) is admitted. Thus, it is possible to consider all samples that exceed the number of six passengers to be noise. In fact, values greater than six are highly underrepresented."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "6f9a9f71",
            "metadata": {},
            "outputs": [],
            "source": [
                "df.groupby('passenger_count').agg(pl.count()).sort('passenger_count')"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "5feda27f",
            "metadata": {},
            "outputs": [],
            "source": [
                "df = df.filter(pl.col('passenger_count') <= 6)"
            ]
        },
        {
            "cell_type": "markdown",
            "id": "b2632f50",
            "metadata": {},
            "source": [
                "## Analyzing spatial locations"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "fe1d2f0e",
            "metadata": {},
            "outputs": [],
            "source": [
                "# train, test = train_test_split(df, test_size=0.2)\n",
                "# train, valid = train_test_split(train, test_size=0.2)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "1e91ef84",
            "metadata": {},
            "outputs": [],
            "source": [
                "def print_point_on_map(ax, x, y, points_area, image, markersize=.5, color='b', title=None):\n",
                "    left, right, bottom, top = points_area\n",
                "    ax.imshow(image, extent=(left, right, bottom, top))\n",
                "    ax.set_ylim(bottom, top)\n",
                "    ax.set_xlim(left, right)\n",
                "    ax.scatter(x, y, markersize, color)\n",
                "    if title is not None:\n",
                "        ax.title.set_text(str(title))"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "813021fb",
            "metadata": {
                "scrolled": true
            },
            "outputs": [],
            "source": [
                "x = df['pickup_longitude'].append(df['dropoff_longitude'])\n",
                "y = df['pickup_latitude'].append(df['dropoff_latitude'])\n",
                "points_area = x.min(), x.max(), y.min(), y.max()\n",
                "\n",
                "# Make the area a square\n",
                "width = data.distance((points_area[0],points_area[2]), (points_area[1],points_area[2]))\n",
                "height = data.distance((points_area[0],points_area[2]), (points_area[0],points_area[3]))\n",
                "\n",
                "additional_space = (width - height)/2\n",
                "\n",
                "new_lat_min, _ = data.find_latitude_correction((points_area[0],points_area[2]), additional_space, b=-1)\n",
                "new_lat_max, _ = data.find_latitude_correction((points_area[0],points_area[3]), additional_space, b=1)\n",
                "\n",
                "points_area = points_area[0], points_area[1], new_lat_min, new_lat_max\n",
                "# print(data.distance((points_area[0],points_area[2]), (points_area[1],points_area[2])))\n",
                "# print(data.distance((points_area[1],points_area[2]), (points_area[1],points_area[3])))\n",
                "# print(data.distance((points_area[1],points_area[3]), (points_area[0],points_area[3])))\n",
                "# print(data.distance((points_area[0],points_area[3]), (points_area[0],points_area[2])))\n",
                "\n",
                "url = 'https://b.basemaps.cartocdn.com/light_nolabels/{z}/{x}/{y}.png'\n",
                "image = data.new_york_map(points_area)\n",
                "\n",
                "plt.imshow(image)\n",
                "plt.show()\n",
                "print(points_area)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "de1b3e8d",
            "metadata": {
                "scrolled": true
            },
            "outputs": [],
            "source": [
                "# Remove points on ocean, not working at the moment\n",
                "ocean_pickup = df.select(\n",
                "    pl.struct(['pickup_longitude', 'pickup_latitude', 'dropoff_longitude', 'dropoff_latitude'])\n",
                "    .map(data.polars_point_on_ocean(points_area, pickup=True))\n",
                "    ).get_columns()[0].alias('ocean_pickup')\n",
                "print(\"pickup done\")\n",
                "ocean_dropoff = df.select(\n",
                "    pl.struct(['pickup_longitude', 'pickup_latitude', 'dropoff_longitude', 'dropoff_latitude'])\n",
                "    .map(data.polars_point_on_ocean(points_area, dropoff=True))\n",
                "    ).get_columns()[0].alias('ocean_dropoff')\n",
                "\n",
                "print('Pickups in the ocean', ocean_pickup.arg_true().shape[0])\n",
                "print('Dropoffs in the ocean', ocean_dropoff.arg_true().shape[0])\n",
                "print('Total ocean outlier samples',\n",
                "      (ocean_dropoff | ocean_pickup).arg_true().shape[0])\n",
                "\n",
                "outsiders_pickup = df.filter(ocean_pickup)\n",
                "outsiders_dropoff = df.filter(ocean_dropoff)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "37652200",
            "metadata": {},
            "outputs": [],
            "source": [
                "fig, axs = plt.subplots(1, 2, figsize=(30, 30))\n",
                "\n",
                "print_point_on_map(axs[0], outsiders_pickup['pickup_longitude'], outsiders_pickup['pickup_latitude'], points_area, image, color='b', markersize=3)\n",
                "print_point_on_map(axs[1], outsiders_dropoff['dropoff_longitude'], outsiders_dropoff['dropoff_latitude'], points_area, image, color='r', markersize=3)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "a7857833",
            "metadata": {},
            "outputs": [],
            "source": [
                "df = df.filter(~ocean_pickup & ~ocean_dropoff)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "60f95cf0",
            "metadata": {},
            "outputs": [],
            "source": [
                "fig, axs = plt.subplots(1, 2, figsize=(50, 50))\n",
                "print_point_on_map(axs[0], df['pickup_longitude'], df['pickup_latitude'], points_area, image, color='b')\n",
                "print_point_on_map(axs[1], df['dropoff_longitude'], df['dropoff_latitude'], points_area, image, color='r')"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "627ad8c8",
            "metadata": {
                "scrolled": false
            },
            "outputs": [],
            "source": [
                "timezone = -5\n",
                "lavorative_hours = (8, 18)\n",
                "\n",
                "day_hours = df.filter((pl.col(\"pickup_datetime\").dt.hour() > lavorative_hours[0]+timezone) & (pl.col(\"pickup_datetime\").dt.hour() < lavorative_hours[1]+timezone))\n",
                "night_hours = df.filter((pl.col(\"pickup_datetime\").dt.hour() <= lavorative_hours[0]+timezone) | (pl.col(\"pickup_datetime\").dt.hour() >= lavorative_hours[1]+timezone))\n",
                "\n",
                "print(len(day_hours), len(night_hours))\n",
                "\n",
                "x_day = day_hours['pickup_longitude'].append(day_hours['dropoff_longitude'])\n",
                "y_day = day_hours['pickup_latitude'].append(day_hours['dropoff_latitude'])\n",
                "\n",
                "x_night = night_hours['pickup_longitude'].append(night_hours['dropoff_longitude'])\n",
                "y_night = night_hours['pickup_latitude'].append(night_hours['dropoff_latitude'])\n",
                "\n",
                "fig, axs = plt.subplots(1, 2, figsize=(16, 16))\n",
                "print_point_on_map(axs[0], x_day, y_day, points_area, image, color='b', markersize=0.1)\n",
                "print_point_on_map(axs[1], x_night, y_night, points_area, image, color='r', markersize=0.1)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "a92b483e",
            "metadata": {
                "scrolled": false
            },
            "outputs": [],
            "source": [
                "hours = []\n",
                "\n",
                "for h in range(5,29):\n",
                "    hour_df = df.filter(pl.col(\"pickup_datetime\").dt.hour() == h % 24)\n",
                "    hours.append((hour_df['pickup_longitude'].append(hour_df['dropoff_longitude']),\n",
                "                  hour_df['pickup_latitude'].append(hour_df['dropoff_latitude']),\n",
                "                  len(hour_df)))\n",
                "    \n",
                "fig, axs = plt.subplots(6, 4, figsize=(16, 20))\n",
                "for h in range(24):\n",
                "    print_point_on_map(axs[h//4, h % 4], hours[h][0], hours[h][1], points_area, image, color='b',\n",
                "                       title=f'{(h) % 24}. {hours[h][2]} rides', markersize=0.05)"
            ]
        },
        {
            "cell_type": "markdown",
            "id": "5413203b",
            "metadata": {},
            "source": [
                "## Time\n",
                "Specific features have to be extracted from timestamps, based on periods and trends."
            ]
        },
        {
            "cell_type": "markdown",
            "id": "64c5ac89",
            "metadata": {},
            "source": [
                "### Monthly-Yearly trend\n",
                "\n",
                "The first thing to investigate is the presence of trends, as detrending data will eventually be necessary before looking for periods. Public transportation rarely becomes cheaper, (at least, that how it is in Bologna). The NYC taxi data spans for about six years, hence, let us look for a yearly trend"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "b892cc9e",
            "metadata": {},
            "outputs": [],
            "source": [
                "plt.scatter(\n",
                "    *df.select(['pickup_datetime', 'fare_amount']).sort('pickup_datetime')\n",
                "    .groupby_dynamic('pickup_datetime', every='1y')\n",
                "    .agg(pl.mean('fare_amount'))\n",
                "    .get_columns())\n",
                "plt.title('Yearly average fare')\n",
                "plt.show()"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "811e68be",
            "metadata": {},
            "outputs": [],
            "source": [
                "df.select(['pickup_datetime', 'fare_amount']).sort('pickup_datetime') \\\n",
                "  .groupby_dynamic('pickup_datetime', every='1y') \\\n",
                "  .agg(pl.col('fare_amount').std().alias('std'))"
            ]
        },
        {
            "cell_type": "markdown",
            "id": "456be33f",
            "metadata": {},
            "source": [
                "Even though variance is pretty high, there is an unambiguous yearly trend (NYC is not that different from Bologna after all). In fact, it is a well known fact that public transportation fares in NYC have been adjusted over time to deal with inflation [2]. In particular, a notable increase happened between 2012 and 2013."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "4e54cb0d",
            "metadata": {},
            "outputs": [],
            "source": [
                "plt.scatter(\n",
                "    *df.select(['pickup_datetime', 'fare_amount']).sort('pickup_datetime')\n",
                "    .filter(pl.col('pickup_datetime').dt.year() == 2012)\n",
                "    .groupby_dynamic('pickup_datetime', every='1mo')\n",
                "    .agg(pl.mean('fare_amount'))\n",
                "    .get_columns())\n",
                "plt.title('Per-month average fares (2012)')\n",
                "plt.show()"
            ]
        },
        {
            "cell_type": "markdown",
            "id": "6490a13b",
            "metadata": {},
            "source": [
                "Further inspection shows that the gap happened in September 2012. In fact, historical record witnesses this. According to the *Fare and Lease Cap Report* of April 2013 [3], during fall 2012 fares have increased by 17%, apparently in order to handle a change in credit card processing fees.\n",
                "\n",
                "Approximating the trend is mandatory in order to proceed with the inspection of periods. Given its nature (inflation) it is acceptable to consider it linear. However, the big gap of September 2012 can be considered anomalous and would clearly skew the linear coefficients. For this reason, two linear trends are considered, with a discontinuity exactly in September 2012."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "652d2c92",
            "metadata": {},
            "outputs": [],
            "source": [
                "# Compute the monthly average fares and split them before/after Sep 2012\n",
                "date_threshold = pl.datetime(2012, 9, 1)\n",
                "\n",
                "months_df = (\n",
                "    df.select(['pickup_datetime', 'fare_amount'])\n",
                "    .sort('pickup_datetime')\n",
                "    .groupby_dynamic('pickup_datetime', every='1mo')\n",
                "    .agg(pl.mean('fare_amount'))\n",
                ")\n",
                "\n",
                "months_pre2012_df = (\n",
                "    months_df.filter(pl.col('pickup_datetime') < date_threshold)\n",
                ")\n",
                "\n",
                "months_post2012_df = (\n",
                "    months_df.filter(pl.col('pickup_datetime') >= date_threshold)\n",
                ")\n",
                "\n",
                "# Sanity check on the dataframe shapes\n",
                "split_month_span = len(months_pre2012_df) + len(months_post2012_df)\n",
                "assert split_month_span == len(months_df)\n",
                "\n",
                "print('Total months', split_month_span)\n",
                "print('Months before Sep 2012:', len(months_pre2012_df))\n",
                "print('Months after Sep 2012:', len(months_post2012_df))"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "abe2701b",
            "metadata": {},
            "outputs": [],
            "source": [
                "# Fit two OLS regressors\n",
                "months_features = np.array(range(len(months_df))).reshape(-1, 1)\n",
                "months_pre2012_features = months_features[:len(months_pre2012_df)]\n",
                "months_post2012_features = months_features[len(months_pre2012_df):]\n",
                "\n",
                "trend_pre2012_regressor = LinearRegression(n_jobs=-1).fit(\n",
                "    months_pre2012_features, months_pre2012_df['fare_amount'])\n",
                "trend_post2012_regressor = LinearRegression(n_jobs=-1).fit(\n",
                "    months_post2012_features, months_post2012_df['fare_amount'])"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "77658ac8",
            "metadata": {},
            "outputs": [],
            "source": [
                "trend_pre2012_pred = trend_pre2012_regressor.predict(months_pre2012_features)\n",
                "trend_post2012_pred = trend_post2012_regressor.predict(months_post2012_features)\n",
                "\n",
                "plt.figure(figsize=(40, 8))\n",
                "plt.plot(*months_df.get_columns())\n",
                "plt.plot(months_df['pickup_datetime'],  np.concatenate((trend_pre2012_pred, trend_post2012_pred)))\n",
                "plt.legend(('Monthly average fare', 'Linear average fare'), fontsize='xx-large')\n",
                "plt.show()"
            ]
        },
        {
            "cell_type": "markdown",
            "id": "3007ca53",
            "metadata": {},
            "source": [
                "The double-linear regression seems to be quite reasonable. This shall result in the extraction of a couple of dedicated features from the timestamps. However, which ones exactly will be discussed after an analysis on periods."
            ]
        },
        {
            "cell_type": "markdown",
            "id": "8c89f382",
            "metadata": {},
            "source": [
                "### Periods\n",
                "A detrended/stationary series can now be computed in order to have a cleaner overview of the periods."
            ]
        },
        {
            "cell_type": "markdown",
            "id": "a59cb889",
            "metadata": {},
            "source": [
                "Starting with the already considered monthly data, detrending exposes clear seasonality. High variance of the computed averages makes the patterns a bit noisy but still, there is a noticeable drop in fares around january each year.\n",
                "\n",
                "Apparently, the city slows down after the holidays, or at least this is what locals suggest [5]. Less demand means less traffic, which results is shorter traversal times and lower average fares (that is, excluding the hypothesis of winter specific fares).\n",
                "\n",
                "Clearly, similar reasoning holds for high season fares (more demand, more traffic). "
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "444c1c5d",
            "metadata": {},
            "outputs": [],
            "source": [
                "plt.figure(figsize=(40, 8))\n",
                "plt.plot(*data.detrend(months_df, trend_pre2012_regressor,\n",
                "                       trend_post2012_regressor, date_threshold)\n",
                "         .get_columns())\n",
                "plt.title('Monthly average fares',\n",
                "          fontsize='xx-large')\n",
                "plt.show()"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "510c37e3",
            "metadata": {},
            "outputs": [],
            "source": []
        },
        {
            "cell_type": "markdown",
            "id": "4d280467",
            "metadata": {},
            "source": [
                "Like in many human processes, days and weeks are destined to have a cyclical nature. These phenomena are however hard to inspect, probably also due to the periods interacting with each other. More sofisticated period extraction could lead to better results, but an empirical approach can still be effective.\n",
                "\n",
                "Grouping samples by hour and plotting a few days or weeks reveals that each day there is a recurrent peak."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "063bd1e1",
            "metadata": {},
            "outputs": [],
            "source": [
                "# NB: Inlcude at least 10mln samples to see the period\n",
                "\n",
                "hours_df = (\n",
                "    df.select(['pickup_datetime', 'fare_amount'])\n",
                "    .sort('pickup_datetime')\n",
                "    .groupby_dynamic('pickup_datetime', every='1h')\n",
                "    .agg(pl.mean('fare_amount'))\n",
                ")\n",
                "\n",
                "# Show period on a certain number of days\n",
                "from_date = pl.datetime(2013, 5, 1)\n",
                "num_of_days = 7\n",
                "\n",
                "plt.figure(figsize=(40, 8))\n",
                "plt.plot(*data.detrend(hours_df, trend_pre2012_regressor,\n",
                "                       trend_post2012_regressor, date_threshold)\n",
                "         .filter(pl.col('pickup_datetime') >= from_date)\n",
                "         [: num_of_days * 24]\n",
                "         .get_columns())\n",
                "plt.grid(axis='x')\n",
                "plt.title('Average fares in a week (2013/05/01 - 2013/05/07)',\n",
                "          fontsize='xx-large')\n",
                "plt.show()"
            ]
        },
        {
            "cell_type": "markdown",
            "id": "c3335e22",
            "metadata": {},
            "source": [
                "Still, even by considering specific weekdays and specific months, there is quite some noise."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "8113b398",
            "metadata": {},
            "outputs": [],
            "source": [
                "plt.figure(figsize=(40, 8))\n",
                "\n",
                "axes = (data.detrend(hours_df, trend_pre2012_regressor,\n",
                "                            trend_post2012_regressor, date_threshold)\n",
                "        .filter((pl.col('pickup_datetime').dt.weekday() == 3)\n",
                "                & (pl.col('pickup_datetime').dt.month() == 1))\n",
                "        .select([pl.col('pickup_datetime').dt.hour(), 'fare_amount'])\n",
                "        .get_columns())\n",
                "\n",
                "sns.violinplot(x=axes[0].to_numpy(), y=axes[1].to_numpy(), cut=0)\n",
                "plt.title('Average fares per hour (wednesdays of january)',\n",
                "          fontsize='xx-large')\n",
                "plt.show()"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "1020a0c4",
            "metadata": {},
            "outputs": [],
            "source": [
                "df = df.with_column(pl.col('pickup_datetime').dt.hour().alias(\"hour\"))\n",
                "df = df.with_column(pl.col('pickup_datetime').dt.weekday().alias(\"week_day\"))\n",
                "df = df.with_column(pl.col('pickup_datetime').dt.month().alias(\"month\"))\n",
                "df = df.with_column(pl.col('pickup_datetime').dt.year().alias(\"year\"))"
            ]
        },
        {
            "cell_type": "markdown",
            "id": "99fbcc8c",
            "metadata": {},
            "source": [
                "In fact, further inspection over specific spatial areas shows that different locations have different conditioned distributions with respect to time. "
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "9ba09e14",
            "metadata": {},
            "outputs": [],
            "source": [
                "jfk_position = (40.653005, -73.797447)\n",
                "manhattan_position = (40.722433, -74.000845)\n",
                "precision = 0.01\n",
                "\n",
                "df_grt_2013 = df.filter((pl.col('pickup_datetime').is_between(pl.datetime(2013, 1, 1), pl.datetime(2100, 1, 1))))\n",
                "df_grt_2013 = df_grt_2013.with_column(pl.col(\"pickup_datetime\").dt.hour().alias('pickup_hour'))\n",
                "\n",
                "df_manhattan = df_grt_2013.filter(((pl.col('pickup_latitude').is_between(manhattan_position[0] - precision, manhattan_position[0] + precision, closed='both')) &\n",
                "                                 (pl.col('pickup_longitude').is_between(manhattan_position[1] - precision, manhattan_position[1] + precision, closed='both'))) |\n",
                "                                 ((pl.col('dropoff_latitude').is_between(manhattan_position[0] - precision, manhattan_position[0] + precision, closed='both')) &\n",
                "                                 (pl.col('dropoff_longitude').is_between(manhattan_position[1] - precision, manhattan_position[1] + precision, closed='both'))))\n",
                "\n",
                "df_jfk = df_grt_2013.filter(((pl.col('pickup_latitude').is_between(jfk_position[0] - precision, jfk_position[0] + precision, closed='both')) &\n",
                "                                 (pl.col('pickup_longitude').is_between(jfk_position[1] - precision, jfk_position[1] + precision, closed='both'))) |\n",
                "                                 ((pl.col('dropoff_latitude').is_between(jfk_position[0] - precision, jfk_position[0] + precision, closed='both')) &\n",
                "                                 (pl.col('dropoff_longitude').is_between(jfk_position[1] - precision, jfk_position[1] + precision, closed='both'))))\n",
                "\n",
                "\n",
                "print(f\"Number of samples from or to jfk: {len(df_jfk)}\")\n",
                "print(f\"Number of samples from or to manhattan: {len(df_manhattan)}\")\n",
                "\n",
                "fg, axs = plt.subplots(2,1, figsize=(40, 8))\n",
                "axs[0].hist(df_manhattan['pickup_hour'], bins=24)\n",
                "axs[0].title.set_text('Hour samples distribution from or to manhattan')\n",
                "\n",
                "axs[1].plot(\n",
                "    *df_manhattan.select(['pickup_hour', 'fare_amount'])\n",
                "    .groupby('pickup_hour')\n",
                "    .agg(pl.mean('fare_amount'))\n",
                "    .sort('pickup_hour')\n",
                "    .get_columns())\n",
                "axs[1].title.set_text(\"Mean hourly fare from or to manhattan\")\n",
                "\n",
                "plt.show()\n",
                "\n",
                "fg, axs = plt.subplots(2,1, figsize=(40, 8))\n",
                "\n",
                "axs[0].hist(df_jfk['pickup_hour'], bins=24)\n",
                "axs[0].title.set_text('Hour samples distribution from or to jfk')\n",
                "\n",
                "axs[1].plot(\n",
                "    *df_jfk.select(['pickup_hour', 'fare_amount'])\n",
                "    .groupby('pickup_hour')\n",
                "    .agg(pl.mean('fare_amount'))\n",
                "    .sort('pickup_hour')\n",
                "    .get_columns())\n",
                "axs[1].title.set_text(\"Mean hourly fare from or to jfk\")\n",
                "\n",
                "plt.show()"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "dae0123a",
            "metadata": {},
            "outputs": [],
            "source": [
                "boros = boroughs.load()\n",
                "\n",
                "boros_image, boros_colors = boroughs.get_image_boroughs(boros, points_area)\n",
                "\n",
                "df = df.with_column(pl.struct(['pickup_longitude', 'pickup_latitude'])\n",
                "                    .map(boroughs.point_boroughs(boros_image, boros_colors, points_area, \"pickup_\")).alias('pickup_borough'))\n",
                "\n",
                "df = df.with_column(pl.struct(['dropoff_longitude', 'dropoff_latitude'])\n",
                "                    .map(boroughs.point_boroughs(boros_image, boros_colors, points_area, \"dropoff_\")).alias('dropoff_borough'))"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "bdcfb183",
            "metadata": {},
            "outputs": [],
            "source": [
                "hood_image, hood_colors = boroughs.get_image_neighborhood(boros, points_area)\n",
                "\n",
                "df = df.with_column(pl.struct(['pickup_longitude', 'pickup_latitude'])\n",
                "                        .map(boroughs.point_boroughs(hood_image, hood_colors, points_area, \"pickup_\")).alias('pickup_hood'))\n",
                "\n",
                "df = df.with_column(pl.struct(['dropoff_longitude', 'dropoff_latitude'])\n",
                "                        .map(boroughs.point_boroughs(hood_image, hood_colors, points_area, \"dropoff_\")).alias('dropoff_hood'))\n",
                "\n",
                "df.head()"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "19330ad0",
            "metadata": {},
            "outputs": [],
            "source": [
                "df_mean_fare_hood = df.groupby('pickup_hood').agg([\n",
                "    pl.count(),\n",
                "    pl.mean('fare_amount')\n",
                "]).sort('count', reverse=True).head(30)\n",
                "\n",
                "fig, ax1 = plt.subplots(figsize=(10,8))\n",
                "\n",
                "fig.autofmt_xdate(rotation=90)\n",
                "ax2 = ax1.twinx()\n",
                "ax1.bar(df_mean_fare_hood['pickup_hood'], df_mean_fare_hood['count'], color='g')\n",
                "ax2.bar(df_mean_fare_hood['pickup_hood'], df_mean_fare_hood['fare_amount'], color='b', width=0.3)\n",
                "\n",
                "ax1.set_xlabel('Neighborhood')\n",
                "ax1.set_ylabel('Samples', color='g')\n",
                "ax2.set_ylabel('Mean fare', color='b')"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "6d700f87",
            "metadata": {},
            "outputs": [],
            "source": [
                "df_same_hood = df.filter(pl.col('pickup_hood') == pl.col('dropoff_hood'))\n",
                "pickup_hoods = [k[0] for k in df_same_hood.select(['pickup_hood']).unique().to_numpy().tolist()]\n",
                "used_hoods = set(pickup_hoods)\n",
                "\n",
                "\n",
                "blocks = math.ceil(math.sqrt(len(used_hoods)))\n",
                "\n",
                "print(f\"There are {len(used_hoods)} neighborhoods\")\n",
                "\n",
                "fig, axs = plt.subplots(blocks, blocks, figsize=(50,50))\n",
                "\n",
                "for k, hood in enumerate(used_hoods):\n",
                "    df_block = df.filter((pl.col('pickup_hood') == hood) & (pl.col('dropoff_hood') == hood))\n",
                "    axs[k//blocks, k % blocks].plot(\n",
                "        *df_block.select(['hour', 'fare_amount'])\n",
                "        .groupby('hour')\n",
                "        .agg(pl.mean('fare_amount'))\n",
                "        .sort('hour')\n",
                "        .get_columns())\n",
                "    axs[k//blocks, k % blocks].title.set_text(hood)"
            ]
        },
        {
            "cell_type": "markdown",
            "id": "7a679339",
            "metadata": {},
            "source": [
                "Since manhattan is the most represented borough in the dataset (and indeed, the most populated one in general), the average distribution was dominated by it, as it can be seen by the grid plot above."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "8753e50c",
            "metadata": {},
            "outputs": [],
            "source": [
                "import importlib\n",
                "importlib.reload(data)"
            ]
        },
        {
            "attachments": {},
            "cell_type": "markdown",
            "id": "1394ad46",
            "metadata": {},
            "source": [
                "# References\n",
                "*TODO: properly cite?*\n",
                "\n",
                "[2]: Why Subway and Bus Fares Are Likely to Rise Next Year, https://www.nytimes.com/2022/12/19/nyregion/why-subway-and-bus-fares-are-likely-to-rise-next-year.html\n",
                "\n",
                "[3]: Fare and Lease Cap Report: April 2013, https://a860-gpp.nyc.gov/concern/nyc_government_publications/jm214q472?locale=en\n",
                "\n",
                "[4]: norta - code for New Orleans Regional Transit Authority Data, https://git.bryanbrattlof.com/norta/about/\n",
                "\n",
                "[5]: The Best Time of Year to Visit NYC, https://www.halfhalftravel.com/travel-guides/best-time-to-visit-nyc.html"
            ]
        }
    ],
    "metadata": {
        "kernelspec": {
            "display_name": "fare-prediction",
            "language": "python",
            "name": "python3"
        },
        "language_info": {
            "codemirror_mode": {
                "name": "ipython",
                "version": 3
            },
            "file_extension": ".py",
            "mimetype": "text/x-python",
            "name": "python",
            "nbconvert_exporter": "python",
            "pygments_lexer": "ipython3",
            "version": "3.10.4"
        },
        "vscode": {
            "interpreter": {
                "hash": "696c235b3b902a0ba4aa434fdc36a015b2219ccdfa906ae5c584142149033b59"
            }
        }
    },
    "nbformat": 4,
    "nbformat_minor": 5
}
