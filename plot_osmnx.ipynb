{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "# OpenStreetMap with OSMnx\n",
    "\n",
    "This example shows how to use OSMnx to download and model a street network\n",
    "from OpenStreetMap, visualize centrality, and save the graph as a shapefile,\n",
    "a GeoPackage, or GraphML.\n",
    "\n",
    "OSMnx is a Python package to retrieve, model, analyze, and visualize\n",
    "OpenStreetMap street networks as NetworkX MultiDiGraph objects. It can also\n",
    "retrieve any other spatial data from OSM as geopandas GeoDataFrames. See\n",
    "https://osmnx.readthedocs.io/ for OSMnx documentation and usage.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import networkx as nx\n",
    "import osmnx as ox\n",
    "import polars as pl\n",
    "from functools import partial\n",
    "import multiprocessing as mp\n",
    "from tqdm import tqdm\n",
    "from taxifare import data\n",
    "from taxifare import boroughs\n",
    "import pickle\n",
    "import os\n",
    "\n",
    "ox.settings.log_console=True\n",
    "ox.settings.use_cache=True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ~ 6m 26s\n",
    "# download street network data from OSM and construct a MultiDiGraph model\n",
    "\n",
    "def load_map(base_map: str, simplified_map: str, tolerance: float) -> nx.MultiDiGraph:\n",
    "    if os.path.exists(simplified_map):\n",
    "        print(f\"loading saved map {simplified_map}\")\n",
    "        H = ox.load_graphml(simplified_map)\n",
    "        print(f\"loaded saved map {simplified_map}\")\n",
    "        return H\n",
    "    elif os.path.exists(base_map):\n",
    "        print(\"Starting to simplify map. May require some time\")\n",
    "        H = ox.simplification._consolidate_intersections_rebuild_graph(\n",
    "            ox.load_graphml(base_map), tolerance=tolerance, reconnect_edges=True)\n",
    "        print(f\"simplified base_map({base_map}) with tollerance = {tolerance}\")\n",
    "        ox.save_graphml(H, filepath=simplified_map)\n",
    "        print(f\"saved simplified graph: {simplified_map}\")\n",
    "        return H\n",
    "    else:\n",
    "        print(\"downloading graph. May require some time\")\n",
    "        G = ox.graph.graph_from_place(\"New York City, New York, USA\")\n",
    "        print(\"downloaded graph\")\n",
    "        G = ox.add_edge_speeds(G)\n",
    "        G = ox.add_edge_travel_times(G)\n",
    "        print(\"added edge speeds and travel times\")\n",
    "        ox.save_graphml(G, filepath=base_map)\n",
    "        print(f\"saved base map: {base_map}\")\n",
    "        print(\"Starting to simplify map. May require some time\")\n",
    "        H = ox.simplification._consolidate_intersections_rebuild_graph(\n",
    "            G, tolerance=tolerance, reconnect_edges=True)\n",
    "        print(f\"simplified with tollerance = {tolerance}\")\n",
    "        ox.save_graphml(H, filepath=simplified_map)\n",
    "        print(f\"saved simplified graph: {simplified_map}\")\n",
    "        return H\n",
    "\n",
    "def plot_graph(G: nx.MultiDiGraph):\n",
    "    fig, ax = ox.plot_graph(\n",
    "        G, bgcolor=\"k\", node_size=5, edge_linewidth=2, edge_color=\"#333333\"\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_map = \"new_york_base.graphml\"\n",
    "tolerance = 0.00025\n",
    "simplified_map = f\"new_york_{tolerance}.graphml\"\n",
    "\n",
    "# load data ~1m 50s\n",
    "G = load_map(base_map, simplified_map, tolerance)\n",
    "df = data.load_data().fetch(500_000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_travel_distance(coords: pl.Series) -> pl.Series :\n",
    "    lon1_series = coords.struct.field('pickup_longitude')\n",
    "    lat1_series = coords.struct.field('pickup_latitude')\n",
    "    lon2_series = coords.struct.field('dropoff_longitude')\n",
    "    lat2_series = coords.struct.field('dropoff_latitude')\n",
    "\n",
    "    n_process = 4\n",
    "    chunksize = 8\n",
    "    partial_travel_distance = partial(data.calculate_travel_distance, G=G)\n",
    "    weights = []\n",
    "    with mp.Pool(processes=n_process) as p:\n",
    "        for travel_time in tqdm(p.imap(partial_travel_distance,\n",
    "                                zip(lon1_series, lat1_series,\n",
    "                                    lon2_series, lat2_series), chunksize),\n",
    "                                    total=len(lon1_series)):\n",
    "            weights.append(travel_time)\n",
    "\n",
    "    return pl.Series(weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.with_columns(pl.struct(['pickup_longitude', 'pickup_latitude', 'dropoff_longitude', 'dropoff_latitude'])\n",
    "                    .map(calculate_travel_distance).alias('travel_time'))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Aproximated distance\n",
    "\n",
    "Instead of calculating the distance for all points we calculate only for pairs of neigborhood"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "G = ox.load_graphml(\"new_york_base.graphml\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "boros = boroughs.load()\n",
    "hoods = []\n",
    "\n",
    "for b in boros.values():\n",
    "    hoods.extend(b['hoods'])\n",
    "\n",
    "hoods_with_centroid = [(h['name'], tuple(h['geometry'].centroid.coords)[0])\n",
    "                       for h in hoods]\n",
    "hoods_with_centroid = sorted(hoods_with_centroid, key=lambda x: x[0])\n",
    "\n",
    "pairs = []\n",
    "for i in range(len(hoods_with_centroid)):\n",
    "    for j in range(i+1, len(hoods_with_centroid)):\n",
    "        pairs.append((hoods_with_centroid[i], hoods_with_centroid[j]))\n",
    "pairs_dict = {(pair[0][0], pair[1][0]): (pair[0][1][0], pair[0][1][1], pair[1][1][0], pair[1][1][1]) for pair in pairs}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_process = 10\n",
    "chunksize = 32\n",
    "\n",
    "partial_travel_distance = partial(data.calculate_travel_distance, G=G)\n",
    "distance_dict = {}\n",
    "keys_list = list(pairs_dict.keys())\n",
    "with mp.Pool(processes=n_process) as p:\n",
    "    index = 0\n",
    "    for travel_time in tqdm(p.imap(partial_travel_distance,\n",
    "                            pairs_dict.values(), chunksize),\n",
    "                                total=len(pairs_dict)):\n",
    "        distance_dict[keys_list[index]] = travel_time\n",
    "        index += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('neighborhoods_pair_distance_0.00025.pickle', 'wb') as f:\n",
    "    pickle.dump(distance_dict, f, protocol=pickle.HIGHEST_PROTOCOL)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
